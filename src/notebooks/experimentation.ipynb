{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25_w,50)-aCMA-ES (mu_w=14.0,w_1=14%) in dimension 834 (seed=765570, Fri Dec 20 15:11:15 2024)\n",
      "Generation 1/20 - Best Fitness: 0.6615164130926132\n",
      "Generation 2/20 - Best Fitness: 0.6134639084339142\n",
      "Generation 3/20 - Best Fitness: 0.5786204263567924\n",
      "Generation 4/20 - Best Fitness: 0.576466754078865\n",
      "Generation 5/20 - Best Fitness: 0.5773473531007767\n",
      "Generation 6/20 - Best Fitness: 0.5842030569911003\n",
      "Generation 7/20 - Best Fitness: 0.5943636372685432\n",
      "Generation 8/20 - Best Fitness: 0.5711185559630394\n",
      "Generation 9/20 - Best Fitness: 0.5828753709793091\n",
      "Generation 10/20 - Best Fitness: 0.5479419082403183\n",
      "Generation 11/20 - Best Fitness: 0.5477472394704819\n",
      "Generation 12/20 - Best Fitness: 0.5302662998437881\n",
      "Generation 13/20 - Best Fitness: 0.5288611426949501\n",
      "Generation 14/20 - Best Fitness: 0.5548508763313293\n",
      "Generation 15/20 - Best Fitness: 0.5456753373146057\n",
      "Generation 16/20 - Best Fitness: 0.5511695593595505\n",
      "Generation 17/20 - Best Fitness: 0.5288901291787624\n",
      "Generation 18/20 - Best Fitness: 0.5211058631539345\n",
      "Generation 19/20 - Best Fitness: 0.5397891253232956\n",
      "Generation 20/20 - Best Fitness: 0.5032380521297455\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cma\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network (e.g., a 2-layer fully connected network)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the fitness function for CMA-ES (this will be the loss of the NN on the training set)\n",
    "def fitness_function(weights, model, dataloader, criterion):\n",
    "    # Unflatten the weights to match the model's architecture\n",
    "    idx = 0\n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()\n",
    "        param.data = torch.tensor(weights[idx: idx + num_params].reshape(param.shape), dtype=torch.float32)\n",
    "        idx += num_params\n",
    "    \n",
    "    # Calculate the loss (fitness) on the validation data\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data, target in dataloader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Function to flatten model weights to a 1D vector (required by CMA-ES)\n",
    "def flatten_weights(model):\n",
    "    return np.concatenate([param.detach().cpu().numpy().flatten() for param in model.parameters()])\n",
    "\n",
    "# Main function to apply CMA-ES optimization on PyTorch model weights\n",
    "def optimize_nn_with_cma(model, dataloader, input_size, hidden_size, output_size, max_generations=10, population_size=20):\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize CMA-ES parameters\n",
    "    initial_weights = flatten_weights(model)  # Flatten the initial model weights\n",
    "    sigma = 0.1  # Initial step size for CMA-ES\n",
    "    \n",
    "    # Apply CMA-ES\n",
    "    es = cma.CMAEvolutionStrategy(initial_weights, sigma, {'popsize': population_size})\n",
    "\n",
    "    # Optimization loop\n",
    "    for generation in range(max_generations):\n",
    "        # Sample a new population of weights\n",
    "        weights_population = es.ask()\n",
    "        \n",
    "        # Evaluate fitness for each candidate solution\n",
    "        fitness_values = []\n",
    "        for weights in weights_population:\n",
    "            fitness = fitness_function(weights, model, dataloader, criterion)\n",
    "            fitness_values.append(fitness)\n",
    "        \n",
    "        # Tell CMA-ES about the fitness of the solutions\n",
    "        es.tell(weights_population, fitness_values)\n",
    "        \n",
    "        # Output the best solution\n",
    "        best_fitness = min(fitness_values)\n",
    "        best_solution = weights_population[np.argmin(fitness_values)]\n",
    "        print(f'Generation {generation + 1}/{max_generations} - Best Fitness: {best_fitness}')\n",
    "        \n",
    "        # Check if the stopping criterion is met (for example, early stopping based on fitness)\n",
    "        if best_fitness < 0.1:  # Example threshold\n",
    "            print(f\"Optimization converged at generation {generation + 1}\")\n",
    "            break\n",
    "\n",
    "    # Return the best model with optimized weights\n",
    "    best_weights = es.result.xbest\n",
    "    idx = 0\n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()\n",
    "        param.data = torch.tensor(best_weights[idx: idx + num_params].reshape(param.shape), dtype=torch.float32)\n",
    "        idx += num_params\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example: training data (use a simple dataset for demonstration)\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.manual_seed(42)\n",
    "X = torch.randn(100, 10)  # 100 samples, 10 features\n",
    "y = torch.randint(0, 2, (100,))  # Binary classification (0 or 1)\n",
    "\n",
    "# Create a DataLoader for the dataset\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 10\n",
    "hidden_size = 64\n",
    "output_size = 2  # Binary classification\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Optimize the model with CMA-ES\n",
    "optimized_model = optimize_nn_with_cma(model, dataloader, input_size, hidden_size, output_size, max_generations=20, population_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/100 - Best Fitness: 4.818201780319214\n",
      "Iteration 5/100 - Best Fitness: 1.510480074211955\n",
      "Iteration 10/100 - Best Fitness: 1.0236693285405636\n",
      "Iteration 15/100 - Best Fitness: 1.0236693285405636\n",
      "Iteration 20/100 - Best Fitness: 0.8858274891972542\n",
      "Iteration 25/100 - Best Fitness: 0.8579841293394566\n",
      "Iteration 30/100 - Best Fitness: 0.8579841293394566\n",
      "Iteration 35/100 - Best Fitness: 0.8579841293394566\n",
      "Iteration 40/100 - Best Fitness: 0.7846528347581625\n",
      "Iteration 45/100 - Best Fitness: 0.7846528347581625\n",
      "Iteration 50/100 - Best Fitness: 0.784250439144671\n",
      "Iteration 55/100 - Best Fitness: 0.784250439144671\n",
      "Iteration 60/100 - Best Fitness: 0.7826134851202369\n",
      "Iteration 65/100 - Best Fitness: 0.7629430741071701\n",
      "Iteration 70/100 - Best Fitness: 0.7038721889257431\n",
      "Iteration 75/100 - Best Fitness: 0.6391522977501154\n",
      "Iteration 80/100 - Best Fitness: 0.6341567635536194\n",
      "Iteration 85/100 - Best Fitness: 0.6341567635536194\n",
      "Iteration 90/100 - Best Fitness: 0.6341567635536194\n",
      "Iteration 95/100 - Best Fitness: 0.6341567635536194\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the same neural network architecture\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Particle Swarm Optimization implementation\n",
    "class PSO:\n",
    "    def __init__(self, n_particles, dim, bounds=None):\n",
    "        self.n_particles = n_particles\n",
    "        self.dim = dim\n",
    "        self.bounds = bounds\n",
    "        \n",
    "        # Initialize particle positions and velocities\n",
    "        self.positions = np.random.randn(n_particles, dim)\n",
    "        self.velocities = np.random.randn(n_particles, dim) * 0.1\n",
    "        \n",
    "        # Initialize best positions and fitness\n",
    "        self.pbest_positions = self.positions.copy()\n",
    "        self.pbest_scores = np.full(n_particles, np.inf)\n",
    "        self.gbest_position = None\n",
    "        self.gbest_score = np.inf\n",
    "        \n",
    "        # PSO parameters\n",
    "        self.w = 0.729  # Inertia weight\n",
    "        self.c1 = 2.05  # Cognitive parameter\n",
    "        self.c2 = 2.05  # Social parameter\n",
    "\n",
    "    def optimize(self, fitness_func, max_iter):\n",
    "        for iteration in range(max_iter):\n",
    "            # Evaluate fitness for all particles\n",
    "            for i in range(self.n_particles):\n",
    "                fitness = fitness_func(self.positions[i])\n",
    "                \n",
    "                # Update personal best\n",
    "                if fitness < self.pbest_scores[i]:\n",
    "                    self.pbest_scores[i] = fitness\n",
    "                    self.pbest_positions[i] = self.positions[i].copy()\n",
    "                \n",
    "                # Update global best\n",
    "                if fitness < self.gbest_score:\n",
    "                    self.gbest_score = fitness\n",
    "                    self.gbest_position = self.positions[i].copy()\n",
    "            \n",
    "            # Update velocities and positions\n",
    "            r1, r2 = np.random.rand(2)\n",
    "            self.velocities = (self.w * self.velocities + \n",
    "                             self.c1 * r1 * (self.pbest_positions - self.positions) +\n",
    "                             self.c2 * r2 * (self.gbest_position - self.positions))\n",
    "            \n",
    "            self.positions += self.velocities\n",
    "            \n",
    "            # Optional: Apply bounds if specified\n",
    "            if self.bounds is not None:\n",
    "                self.positions = np.clip(self.positions, self.bounds[0], self.bounds[1])\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                print(f'Iteration {iteration}/{max_iter} - Best Fitness: {self.gbest_score}')\n",
    "            \n",
    "            # Early stopping condition\n",
    "            if self.gbest_score < 0.1:\n",
    "                print(f\"Optimization converged at iteration {iteration}\")\n",
    "                break\n",
    "        \n",
    "        return self.gbest_position, self.gbest_score\n",
    "\n",
    "# Fitness function for neural network\n",
    "def fitness_function(weights, model, dataloader, criterion):\n",
    "    # Unflatten the weights to match the model's architecture\n",
    "    idx = 0\n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()\n",
    "        param.data = torch.tensor(weights[idx:idx + num_params].reshape(param.shape), dtype=torch.float32)\n",
    "        idx += num_params\n",
    "    \n",
    "    # Calculate the loss (fitness) on the validation data\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Function to flatten model weights\n",
    "def flatten_weights(model):\n",
    "    return np.concatenate([param.detach().cpu().numpy().flatten() for param in model.parameters()])\n",
    "\n",
    "# Main function to apply PSO optimization on PyTorch model weights\n",
    "def optimize_nn_with_pso(model, dataloader, input_size, hidden_size, output_size, max_iterations=100, n_particles=50):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Get the total number of parameters in the model\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    # Initialize PSO\n",
    "    pso = PSO(n_particles=n_particles, dim=n_params)\n",
    "    \n",
    "    # Create a wrapper for the fitness function\n",
    "    def fitness_wrapper(weights):\n",
    "        return fitness_function(weights, model, dataloader, criterion)\n",
    "    \n",
    "    # Run PSO optimization\n",
    "    best_weights, best_fitness = pso.optimize(fitness_wrapper, max_iterations)\n",
    "    \n",
    "    # Update the model with the best weights found\n",
    "    idx = 0\n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()\n",
    "        param.data = torch.tensor(best_weights[idx:idx + num_params].reshape(param.shape), dtype=torch.float32)\n",
    "        idx += num_params\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create synthetic dataset\n",
    "    X = torch.randn(100, 10)  # 100 samples, 10 features\n",
    "    y = torch.randint(0, 2, (100,))  # Binary classification\n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataset = torch.utils.data.TensorDataset(X, y)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    input_size = 10\n",
    "    hidden_size = 64\n",
    "    output_size = 2\n",
    "    model = SimpleNN(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # Optimize the model with PSO\n",
    "    optimized_model = optimize_nn_with_pso(\n",
    "        model, \n",
    "        dataloader,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "        max_iterations=100,\n",
    "        n_particles=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature decreased to 0.297000, Current best loss: 0.697569\n",
      "Temperature decreased to 0.294030, Current best loss: 0.697569\n",
      "Temperature decreased to 0.291090, Current best loss: 0.697569\n",
      "Temperature decreased to 0.288179, Current best loss: 0.697569\n",
      "Temperature decreased to 0.285297, Current best loss: 0.697569\n",
      "Temperature decreased to 0.282444, Current best loss: 0.697569\n",
      "Temperature decreased to 0.279620, Current best loss: 0.697569\n",
      "Temperature decreased to 0.276823, Current best loss: 0.697569\n",
      "Temperature decreased to 0.274055, Current best loss: 0.697569\n",
      "Temperature decreased to 0.271315, Current best loss: 0.697569\n",
      "Temperature decreased to 0.268601, Current best loss: 0.697569\n",
      "Temperature decreased to 0.265915, Current best loss: 0.697569\n",
      "Temperature decreased to 0.263256, Current best loss: 0.697569\n",
      "Temperature decreased to 0.260624, Current best loss: 0.697569\n",
      "Temperature decreased to 0.258018, Current best loss: 0.697569\n",
      "Temperature decreased to 0.255437, Current best loss: 0.697569\n",
      "Temperature decreased to 0.252883, Current best loss: 0.697569\n",
      "Temperature decreased to 0.250354, Current best loss: 0.697569\n",
      "Temperature decreased to 0.247851, Current best loss: 0.697569\n",
      "Temperature decreased to 0.245372, Current best loss: 0.697569\n",
      "Temperature decreased to 0.242918, Current best loss: 0.697569\n",
      "Temperature decreased to 0.240489, Current best loss: 0.697569\n",
      "Temperature decreased to 0.238084, Current best loss: 0.697569\n",
      "Temperature decreased to 0.235703, Current best loss: 0.697569\n",
      "Temperature decreased to 0.233346, Current best loss: 0.697569\n",
      "Temperature decreased to 0.231013, Current best loss: 0.697569\n",
      "Temperature decreased to 0.228703, Current best loss: 0.697569\n",
      "Temperature decreased to 0.226416, Current best loss: 0.697569\n",
      "Temperature decreased to 0.224152, Current best loss: 0.697569\n",
      "Temperature decreased to 0.221910, Current best loss: 0.697569\n",
      "Temperature decreased to 0.219691, Current best loss: 0.697569\n",
      "Temperature decreased to 0.217494, Current best loss: 0.697569\n",
      "Temperature decreased to 0.215319, Current best loss: 0.697569\n",
      "Temperature decreased to 0.213166, Current best loss: 0.697569\n",
      "Temperature decreased to 0.211034, Current best loss: 0.697569\n",
      "Temperature decreased to 0.208924, Current best loss: 0.697569\n",
      "Temperature decreased to 0.206835, Current best loss: 0.697569\n",
      "Temperature decreased to 0.204766, Current best loss: 0.697569\n",
      "Temperature decreased to 0.202719, Current best loss: 0.697569\n",
      "Temperature decreased to 0.200692, Current best loss: 0.697569\n",
      "Temperature decreased to 0.198685, Current best loss: 0.697569\n",
      "Temperature decreased to 0.196698, Current best loss: 0.697569\n",
      "Temperature decreased to 0.194731, Current best loss: 0.697569\n",
      "Temperature decreased to 0.192783, Current best loss: 0.697569\n",
      "Temperature decreased to 0.190856, Current best loss: 0.697569\n",
      "Temperature decreased to 0.188947, Current best loss: 0.697569\n",
      "Temperature decreased to 0.187058, Current best loss: 0.697569\n",
      "Temperature decreased to 0.185187, Current best loss: 0.697569\n",
      "Temperature decreased to 0.183335, Current best loss: 0.697569\n",
      "Temperature decreased to 0.181502, Current best loss: 0.697569\n",
      "Temperature decreased to 0.179687, Current best loss: 0.697569\n",
      "Temperature decreased to 0.177890, Current best loss: 0.697569\n",
      "Temperature decreased to 0.176111, Current best loss: 0.697569\n",
      "Temperature decreased to 0.174350, Current best loss: 0.697569\n",
      "Temperature decreased to 0.172606, Current best loss: 0.697569\n",
      "Temperature decreased to 0.170880, Current best loss: 0.697569\n",
      "Temperature decreased to 0.169172, Current best loss: 0.697569\n",
      "Temperature decreased to 0.167480, Current best loss: 0.697569\n",
      "Temperature decreased to 0.165805, Current best loss: 0.697569\n",
      "Temperature decreased to 0.164147, Current best loss: 0.697569\n",
      "Temperature decreased to 0.162506, Current best loss: 0.697569\n",
      "Temperature decreased to 0.160880, Current best loss: 0.697569\n",
      "Temperature decreased to 0.159272, Current best loss: 0.697569\n",
      "Temperature decreased to 0.157679, Current best loss: 0.697569\n",
      "Temperature decreased to 0.156102, Current best loss: 0.697569\n",
      "Temperature decreased to 0.154541, Current best loss: 0.697569\n",
      "Temperature decreased to 0.152996, Current best loss: 0.697569\n",
      "Temperature decreased to 0.151466, Current best loss: 0.697569\n",
      "Temperature decreased to 0.149951, Current best loss: 0.697569\n",
      "Temperature decreased to 0.148452, Current best loss: 0.697569\n",
      "Temperature decreased to 0.146967, Current best loss: 0.697569\n",
      "Temperature decreased to 0.145497, Current best loss: 0.697569\n",
      "Temperature decreased to 0.144042, Current best loss: 0.697569\n",
      "Temperature decreased to 0.142602, Current best loss: 0.697569\n",
      "Temperature decreased to 0.141176, Current best loss: 0.697569\n",
      "Temperature decreased to 0.139764, Current best loss: 0.697569\n",
      "Temperature decreased to 0.138367, Current best loss: 0.697569\n",
      "Temperature decreased to 0.136983, Current best loss: 0.697569\n",
      "Temperature decreased to 0.135613, Current best loss: 0.697569\n",
      "Temperature decreased to 0.134257, Current best loss: 0.697569\n",
      "Temperature decreased to 0.132914, Current best loss: 0.697569\n",
      "Temperature decreased to 0.131585, Current best loss: 0.697569\n",
      "Temperature decreased to 0.130269, Current best loss: 0.697569\n",
      "Temperature decreased to 0.128967, Current best loss: 0.697569\n",
      "Temperature decreased to 0.127677, Current best loss: 0.697569\n",
      "Temperature decreased to 0.126400, Current best loss: 0.697569\n",
      "Temperature decreased to 0.125136, Current best loss: 0.697569\n",
      "Temperature decreased to 0.123885, Current best loss: 0.697569\n",
      "Temperature decreased to 0.122646, Current best loss: 0.697569\n",
      "Temperature decreased to 0.121420, Current best loss: 0.697569\n",
      "Temperature decreased to 0.120205, Current best loss: 0.697569\n",
      "Temperature decreased to 0.119003, Current best loss: 0.697569\n",
      "Temperature decreased to 0.117813, Current best loss: 0.697569\n",
      "Temperature decreased to 0.116635, Current best loss: 0.697569\n",
      "Temperature decreased to 0.115469, Current best loss: 0.697569\n",
      "Temperature decreased to 0.114314, Current best loss: 0.697569\n",
      "Temperature decreased to 0.113171, Current best loss: 0.697569\n",
      "Temperature decreased to 0.112039, Current best loss: 0.697569\n",
      "Temperature decreased to 0.110919, Current best loss: 0.697569\n",
      "Temperature decreased to 0.109810, Current best loss: 0.697569\n",
      "Temperature decreased to 0.108712, Current best loss: 0.697569\n",
      "Temperature decreased to 0.107624, Current best loss: 0.697569\n",
      "Temperature decreased to 0.106548, Current best loss: 0.697569\n",
      "Temperature decreased to 0.105483, Current best loss: 0.697569\n",
      "Temperature decreased to 0.104428, Current best loss: 0.697569\n",
      "Temperature decreased to 0.103384, Current best loss: 0.697569\n",
      "Temperature decreased to 0.102350, Current best loss: 0.697569\n",
      "Temperature decreased to 0.101326, Current best loss: 0.697569\n",
      "Temperature decreased to 0.100313, Current best loss: 0.697569\n",
      "Temperature decreased to 0.099310, Current best loss: 0.697569\n",
      "Temperature decreased to 0.098317, Current best loss: 0.697569\n",
      "Temperature decreased to 0.097334, Current best loss: 0.697569\n",
      "Temperature decreased to 0.096360, Current best loss: 0.697569\n",
      "Temperature decreased to 0.095397, Current best loss: 0.697569\n",
      "Temperature decreased to 0.094443, Current best loss: 0.697569\n",
      "Temperature decreased to 0.093498, Current best loss: 0.697569\n",
      "Temperature decreased to 0.092563, Current best loss: 0.697569\n",
      "Temperature decreased to 0.091638, Current best loss: 0.697569\n",
      "Temperature decreased to 0.090721, Current best loss: 0.697569\n",
      "Temperature decreased to 0.089814, Current best loss: 0.697569\n",
      "Temperature decreased to 0.088916, Current best loss: 0.697569\n",
      "Temperature decreased to 0.088027, Current best loss: 0.697569\n",
      "Temperature decreased to 0.087147, Current best loss: 0.697569\n",
      "Temperature decreased to 0.086275, Current best loss: 0.697569\n",
      "Temperature decreased to 0.085412, Current best loss: 0.697569\n",
      "Temperature decreased to 0.084558, Current best loss: 0.697569\n",
      "Temperature decreased to 0.083713, Current best loss: 0.697569\n",
      "Temperature decreased to 0.082876, Current best loss: 0.697569\n",
      "Temperature decreased to 0.082047, Current best loss: 0.697569\n",
      "Temperature decreased to 0.081226, Current best loss: 0.697569\n",
      "Temperature decreased to 0.080414, Current best loss: 0.697569\n",
      "Temperature decreased to 0.079610, Current best loss: 0.697569\n",
      "Temperature decreased to 0.078814, Current best loss: 0.697569\n",
      "Temperature decreased to 0.078026, Current best loss: 0.697569\n",
      "Temperature decreased to 0.077245, Current best loss: 0.697569\n",
      "Temperature decreased to 0.076473, Current best loss: 0.697569\n",
      "Temperature decreased to 0.075708, Current best loss: 0.697569\n",
      "Temperature decreased to 0.074951, Current best loss: 0.697569\n",
      "Temperature decreased to 0.074202, Current best loss: 0.697569\n",
      "Temperature decreased to 0.073460, Current best loss: 0.697569\n",
      "Temperature decreased to 0.072725, Current best loss: 0.697569\n",
      "Temperature decreased to 0.071998, Current best loss: 0.697569\n",
      "Temperature decreased to 0.071278, Current best loss: 0.697569\n",
      "Temperature decreased to 0.070565, Current best loss: 0.697569\n",
      "Temperature decreased to 0.069859, Current best loss: 0.697569\n",
      "Temperature decreased to 0.069161, Current best loss: 0.697569\n",
      "Temperature decreased to 0.068469, Current best loss: 0.697569\n",
      "Temperature decreased to 0.067784, Current best loss: 0.697569\n",
      "Temperature decreased to 0.067107, Current best loss: 0.697569\n",
      "Temperature decreased to 0.066436, Current best loss: 0.697569\n",
      "Temperature decreased to 0.065771, Current best loss: 0.697569\n",
      "Temperature decreased to 0.065113, Current best loss: 0.697569\n",
      "Temperature decreased to 0.064462, Current best loss: 0.697569\n",
      "Temperature decreased to 0.063818, Current best loss: 0.697569\n",
      "Temperature decreased to 0.063180, Current best loss: 0.697569\n",
      "Temperature decreased to 0.062548, Current best loss: 0.697569\n",
      "Temperature decreased to 0.061922, Current best loss: 0.697569\n",
      "Temperature decreased to 0.061303, Current best loss: 0.697569\n",
      "Temperature decreased to 0.060690, Current best loss: 0.697569\n",
      "Temperature decreased to 0.060083, Current best loss: 0.697569\n",
      "Temperature decreased to 0.059482, Current best loss: 0.697569\n",
      "Temperature decreased to 0.058887, Current best loss: 0.697569\n",
      "Temperature decreased to 0.058299, Current best loss: 0.697569\n",
      "Temperature decreased to 0.057716, Current best loss: 0.697569\n",
      "Temperature decreased to 0.057138, Current best loss: 0.697569\n",
      "Temperature decreased to 0.056567, Current best loss: 0.697569\n",
      "Temperature decreased to 0.056001, Current best loss: 0.697569\n",
      "Temperature decreased to 0.055441, Current best loss: 0.697569\n",
      "Temperature decreased to 0.054887, Current best loss: 0.697569\n",
      "Temperature decreased to 0.054338, Current best loss: 0.697569\n",
      "Temperature decreased to 0.053795, Current best loss: 0.697569\n",
      "Temperature decreased to 0.053257, Current best loss: 0.697569\n",
      "Temperature decreased to 0.052724, Current best loss: 0.697569\n",
      "Temperature decreased to 0.052197, Current best loss: 0.697569\n",
      "Temperature decreased to 0.051675, Current best loss: 0.697569\n",
      "Temperature decreased to 0.051158, Current best loss: 0.697569\n",
      "Temperature decreased to 0.050647, Current best loss: 0.697569\n",
      "Temperature decreased to 0.050140, Current best loss: 0.697569\n",
      "Temperature decreased to 0.049639, Current best loss: 0.697569\n",
      "Temperature decreased to 0.049142, Current best loss: 0.697569\n",
      "Temperature decreased to 0.048651, Current best loss: 0.697569\n",
      "Temperature decreased to 0.048164, Current best loss: 0.697569\n",
      "Temperature decreased to 0.047683, Current best loss: 0.697569\n",
      "Temperature decreased to 0.047206, Current best loss: 0.697569\n",
      "Temperature decreased to 0.046734, Current best loss: 0.697569\n",
      "Temperature decreased to 0.046267, Current best loss: 0.697569\n",
      "Temperature decreased to 0.045804, Current best loss: 0.697569\n",
      "Temperature decreased to 0.045346, Current best loss: 0.697569\n",
      "Temperature decreased to 0.044892, Current best loss: 0.697569\n",
      "Temperature decreased to 0.044443, Current best loss: 0.697569\n",
      "Temperature decreased to 0.043999, Current best loss: 0.697569\n",
      "Temperature decreased to 0.043559, Current best loss: 0.697569\n",
      "Temperature decreased to 0.043123, Current best loss: 0.697569\n",
      "Temperature decreased to 0.042692, Current best loss: 0.697569\n",
      "Temperature decreased to 0.042265, Current best loss: 0.697569\n",
      "Temperature decreased to 0.041843, Current best loss: 0.697569\n",
      "Temperature decreased to 0.041424, Current best loss: 0.697569\n",
      "Temperature decreased to 0.041010, Current best loss: 0.697569\n",
      "Temperature decreased to 0.040600, Current best loss: 0.697569\n",
      "Temperature decreased to 0.040194, Current best loss: 0.697569\n",
      "Temperature decreased to 0.039792, Current best loss: 0.697569\n",
      "Temperature decreased to 0.039394, Current best loss: 0.697569\n",
      "Temperature decreased to 0.039000, Current best loss: 0.697569\n",
      "Temperature decreased to 0.038610, Current best loss: 0.697569\n",
      "Temperature decreased to 0.038224, Current best loss: 0.697569\n",
      "Temperature decreased to 0.037842, Current best loss: 0.697569\n",
      "Temperature decreased to 0.037463, Current best loss: 0.697569\n",
      "Temperature decreased to 0.037089, Current best loss: 0.697569\n",
      "Temperature decreased to 0.036718, Current best loss: 0.697569\n",
      "Temperature decreased to 0.036351, Current best loss: 0.697569\n",
      "Temperature decreased to 0.035987, Current best loss: 0.697569\n",
      "Temperature decreased to 0.035627, Current best loss: 0.697569\n",
      "Temperature decreased to 0.035271, Current best loss: 0.697569\n",
      "Temperature decreased to 0.034918, Current best loss: 0.697569\n",
      "Temperature decreased to 0.034569, Current best loss: 0.697569\n",
      "Temperature decreased to 0.034223, Current best loss: 0.697569\n",
      "Temperature decreased to 0.033881, Current best loss: 0.697569\n",
      "Temperature decreased to 0.033542, Current best loss: 0.697569\n",
      "Temperature decreased to 0.033207, Current best loss: 0.697569\n",
      "Temperature decreased to 0.032875, Current best loss: 0.697569\n",
      "Temperature decreased to 0.032546, Current best loss: 0.697569\n",
      "Temperature decreased to 0.032221, Current best loss: 0.697569\n",
      "Temperature decreased to 0.031898, Current best loss: 0.697569\n",
      "Temperature decreased to 0.031579, Current best loss: 0.697569\n",
      "Temperature decreased to 0.031264, Current best loss: 0.697569\n",
      "Temperature decreased to 0.030951, Current best loss: 0.697569\n",
      "Temperature decreased to 0.030642, Current best loss: 0.697569\n",
      "Temperature decreased to 0.030335, Current best loss: 0.697569\n",
      "Temperature decreased to 0.030032, Current best loss: 0.697569\n",
      "Temperature decreased to 0.029731, Current best loss: 0.697569\n",
      "Temperature decreased to 0.029434, Current best loss: 0.697569\n",
      "Temperature decreased to 0.029140, Current best loss: 0.697569\n",
      "Temperature decreased to 0.028848, Current best loss: 0.697569\n",
      "Temperature decreased to 0.028560, Current best loss: 0.697569\n",
      "Temperature decreased to 0.028274, Current best loss: 0.697569\n",
      "Temperature decreased to 0.027992, Current best loss: 0.697569\n",
      "Temperature decreased to 0.027712, Current best loss: 0.697569\n",
      "Temperature decreased to 0.027435, Current best loss: 0.697569\n",
      "Temperature decreased to 0.027160, Current best loss: 0.697569\n",
      "Temperature decreased to 0.026889, Current best loss: 0.697569\n",
      "Temperature decreased to 0.026620, Current best loss: 0.697569\n",
      "Temperature decreased to 0.026354, Current best loss: 0.697569\n",
      "Temperature decreased to 0.026090, Current best loss: 0.697569\n",
      "Temperature decreased to 0.025829, Current best loss: 0.697569\n",
      "Temperature decreased to 0.025571, Current best loss: 0.697569\n",
      "Temperature decreased to 0.025315, Current best loss: 0.697569\n",
      "Temperature decreased to 0.025062, Current best loss: 0.697569\n",
      "Temperature decreased to 0.024811, Current best loss: 0.697569\n",
      "Temperature decreased to 0.024563, Current best loss: 0.697569\n",
      "Temperature decreased to 0.024318, Current best loss: 0.697569\n",
      "Temperature decreased to 0.024074, Current best loss: 0.697569\n",
      "Temperature decreased to 0.023834, Current best loss: 0.697569\n",
      "Temperature decreased to 0.023595, Current best loss: 0.697569\n",
      "Temperature decreased to 0.023359, Current best loss: 0.697569\n",
      "Temperature decreased to 0.023126, Current best loss: 0.697569\n",
      "Temperature decreased to 0.022894, Current best loss: 0.697569\n",
      "Temperature decreased to 0.022666, Current best loss: 0.697569\n",
      "Temperature decreased to 0.022439, Current best loss: 0.697569\n",
      "Temperature decreased to 0.022215, Current best loss: 0.697569\n",
      "Temperature decreased to 0.021992, Current best loss: 0.697569\n",
      "Temperature decreased to 0.021772, Current best loss: 0.697569\n",
      "Temperature decreased to 0.021555, Current best loss: 0.697569\n",
      "Temperature decreased to 0.021339, Current best loss: 0.697569\n",
      "Temperature decreased to 0.021126, Current best loss: 0.697569\n",
      "Temperature decreased to 0.020915, Current best loss: 0.697569\n",
      "Temperature decreased to 0.020705, Current best loss: 0.697569\n",
      "Temperature decreased to 0.020498, Current best loss: 0.697569\n",
      "Temperature decreased to 0.020293, Current best loss: 0.697569\n",
      "Temperature decreased to 0.020090, Current best loss: 0.697569\n",
      "Temperature decreased to 0.019889, Current best loss: 0.697569\n",
      "Temperature decreased to 0.019691, Current best loss: 0.697569\n",
      "Temperature decreased to 0.019494, Current best loss: 0.697569\n",
      "Iteration 272, Temperature: 0.019494, New Best Loss: 0.667707\n",
      "Temperature decreased to 0.019299, Current best loss: 0.667707\n",
      "Iteration 273, Temperature: 0.019299, New Best Loss: 0.657480\n",
      "Iteration 273, Temperature: 0.019299, New Best Loss: 0.633431\n",
      "Temperature decreased to 0.019106, Current best loss: 0.633431\n",
      "Iteration 274, Temperature: 0.019106, New Best Loss: 0.595530\n",
      "Iteration 274, Temperature: 0.019106, New Best Loss: 0.580578\n",
      "Temperature decreased to 0.018915, Current best loss: 0.580578\n",
      "Iteration 275, Temperature: 0.018915, New Best Loss: 0.554378\n",
      "Temperature decreased to 0.018726, Current best loss: 0.554378\n",
      "Iteration 276, Temperature: 0.018726, New Best Loss: 0.550886\n",
      "Temperature decreased to 0.018538, Current best loss: 0.550886\n",
      "Temperature decreased to 0.018353, Current best loss: 0.550886\n",
      "Iteration 278, Temperature: 0.018353, New Best Loss: 0.544377\n",
      "Temperature decreased to 0.018169, Current best loss: 0.544377\n",
      "Temperature decreased to 0.017988, Current best loss: 0.544377\n",
      "Iteration 280, Temperature: 0.017988, New Best Loss: 0.534971\n",
      "Iteration 280, Temperature: 0.017988, New Best Loss: 0.534406\n",
      "Iteration 280, Temperature: 0.017988, New Best Loss: 0.530235\n",
      "Temperature decreased to 0.017808, Current best loss: 0.530235\n",
      "Temperature decreased to 0.017630, Current best loss: 0.530235\n",
      "Temperature decreased to 0.017453, Current best loss: 0.530235\n",
      "Temperature decreased to 0.017279, Current best loss: 0.530235\n",
      "Temperature decreased to 0.017106, Current best loss: 0.530235\n",
      "Iteration 285, Temperature: 0.017106, New Best Loss: 0.529820\n",
      "Temperature decreased to 0.016935, Current best loss: 0.529820\n",
      "Iteration 286, Temperature: 0.016935, New Best Loss: 0.518233\n",
      "Temperature decreased to 0.016766, Current best loss: 0.518233\n",
      "Temperature decreased to 0.016598, Current best loss: 0.518233\n",
      "Temperature decreased to 0.016432, Current best loss: 0.518233\n",
      "Iteration 289, Temperature: 0.016432, New Best Loss: 0.515078\n",
      "Temperature decreased to 0.016268, Current best loss: 0.515078\n",
      "Temperature decreased to 0.016105, Current best loss: 0.515078\n",
      "Temperature decreased to 0.015944, Current best loss: 0.515078\n",
      "Temperature decreased to 0.015785, Current best loss: 0.515078\n",
      "Temperature decreased to 0.015627, Current best loss: 0.515078\n",
      "Temperature decreased to 0.015470, Current best loss: 0.515078\n",
      "Temperature decreased to 0.015316, Current best loss: 0.515078\n",
      "Iteration 296, Temperature: 0.015316, New Best Loss: 0.511567\n",
      "Iteration 296, Temperature: 0.015316, New Best Loss: 0.495166\n",
      "Temperature decreased to 0.015163, Current best loss: 0.495166\n",
      "Iteration 297, Temperature: 0.015163, New Best Loss: 0.488942\n",
      "Temperature decreased to 0.015011, Current best loss: 0.488942\n",
      "Temperature decreased to 0.014861, Current best loss: 0.488942\n",
      "Temperature decreased to 0.014712, Current best loss: 0.488942\n",
      "Temperature decreased to 0.014565, Current best loss: 0.488942\n",
      "Temperature decreased to 0.014419, Current best loss: 0.488942\n",
      "Temperature decreased to 0.014275, Current best loss: 0.488942\n",
      "Temperature decreased to 0.014133, Current best loss: 0.488942\n",
      "Temperature decreased to 0.013991, Current best loss: 0.488942\n",
      "Temperature decreased to 0.013851, Current best loss: 0.488942\n",
      "Temperature decreased to 0.013713, Current best loss: 0.488942\n",
      "Temperature decreased to 0.013576, Current best loss: 0.488942\n",
      "Temperature decreased to 0.013440, Current best loss: 0.488942\n",
      "Temperature decreased to 0.013306, Current best loss: 0.488942\n",
      "Temperature decreased to 0.013172, Current best loss: 0.488942\n",
      "Iteration 311, Temperature: 0.013172, New Best Loss: 0.487566\n",
      "Iteration 311, Temperature: 0.013172, New Best Loss: 0.472666\n",
      "Iteration 311, Temperature: 0.013172, New Best Loss: 0.465567\n",
      "Iteration 311, Temperature: 0.013172, New Best Loss: 0.456298\n",
      "Temperature decreased to 0.013041, Current best loss: 0.456298\n",
      "Temperature decreased to 0.012910, Current best loss: 0.456298\n",
      "Temperature decreased to 0.012781, Current best loss: 0.456298\n",
      "Iteration 314, Temperature: 0.012781, New Best Loss: 0.449305\n",
      "Iteration 314, Temperature: 0.012781, New Best Loss: 0.420993\n",
      "Temperature decreased to 0.012653, Current best loss: 0.420993\n",
      "Temperature decreased to 0.012527, Current best loss: 0.420993\n",
      "Iteration 316, Temperature: 0.012527, New Best Loss: 0.420838\n",
      "Temperature decreased to 0.012402, Current best loss: 0.420838\n",
      "Iteration 317, Temperature: 0.012402, New Best Loss: 0.419743\n",
      "Temperature decreased to 0.012278, Current best loss: 0.419743\n",
      "Iteration 318, Temperature: 0.012278, New Best Loss: 0.417675\n",
      "Temperature decreased to 0.012155, Current best loss: 0.417675\n",
      "Temperature decreased to 0.012033, Current best loss: 0.417675\n",
      "Temperature decreased to 0.011913, Current best loss: 0.417675\n",
      "Temperature decreased to 0.011794, Current best loss: 0.417675\n",
      "Temperature decreased to 0.011676, Current best loss: 0.417675\n",
      "Temperature decreased to 0.011559, Current best loss: 0.417675\n",
      "Temperature decreased to 0.011444, Current best loss: 0.417675\n",
      "Temperature decreased to 0.011329, Current best loss: 0.417675\n",
      "Temperature decreased to 0.011216, Current best loss: 0.417675\n",
      "Temperature decreased to 0.011104, Current best loss: 0.417675\n",
      "Temperature decreased to 0.010993, Current best loss: 0.417675\n",
      "Iteration 329, Temperature: 0.010993, New Best Loss: 0.413371\n",
      "Temperature decreased to 0.010883, Current best loss: 0.413371\n",
      "Temperature decreased to 0.010774, Current best loss: 0.413371\n",
      "Iteration 331, Temperature: 0.010774, New Best Loss: 0.408292\n",
      "Iteration 331, Temperature: 0.010774, New Best Loss: 0.407029\n",
      "Temperature decreased to 0.010666, Current best loss: 0.407029\n",
      "Iteration 332, Temperature: 0.010666, New Best Loss: 0.397779\n",
      "Iteration 332, Temperature: 0.010666, New Best Loss: 0.386049\n",
      "Iteration 332, Temperature: 0.010666, New Best Loss: 0.384665\n",
      "Iteration 332, Temperature: 0.010666, New Best Loss: 0.379136\n",
      "Temperature decreased to 0.010559, Current best loss: 0.379136\n",
      "Iteration 333, Temperature: 0.010559, New Best Loss: 0.378694\n",
      "Iteration 333, Temperature: 0.010559, New Best Loss: 0.375538\n",
      "Iteration 333, Temperature: 0.010559, New Best Loss: 0.364618\n",
      "Temperature decreased to 0.010454, Current best loss: 0.364618\n",
      "Iteration 334, Temperature: 0.010454, New Best Loss: 0.362519\n",
      "Iteration 334, Temperature: 0.010454, New Best Loss: 0.358581\n",
      "Temperature decreased to 0.010349, Current best loss: 0.358581\n",
      "Iteration 335, Temperature: 0.010349, New Best Loss: 0.352581\n",
      "Temperature decreased to 0.010246, Current best loss: 0.352581\n",
      "Iteration 336, Temperature: 0.010246, New Best Loss: 0.351027\n",
      "Iteration 336, Temperature: 0.010246, New Best Loss: 0.346800\n",
      "Iteration 336, Temperature: 0.010246, New Best Loss: 0.344595\n",
      "Temperature decreased to 0.010143, Current best loss: 0.344595\n",
      "Iteration 337, Temperature: 0.010143, New Best Loss: 0.343766\n",
      "Iteration 337, Temperature: 0.010143, New Best Loss: 0.343193\n",
      "Temperature decreased to 0.010042, Current best loss: 0.343193\n",
      "Temperature decreased to 0.009942, Current best loss: 0.343193\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define a simple neural network (same as before)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to calculate model loss (fitness)\n",
    "def calculate_loss(weights, model, dataloader, criterion):\n",
    "    # Unflatten the weights to match the model's architecture\n",
    "    idx = 0\n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()\n",
    "        param.data = torch.tensor(weights[idx: idx + num_params].reshape(param.shape), dtype=torch.float32)\n",
    "        idx += num_params\n",
    "    \n",
    "    # Calculate the loss on the validation data\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data, target in dataloader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Function to get flattened weights\n",
    "def get_flat_weights(model):\n",
    "    return np.concatenate([param.detach().cpu().numpy().flatten() for param in model.parameters()])\n",
    "\n",
    "# Function to generate neighbor solution\n",
    "def generate_neighbor(weights, temperature):\n",
    "    # Scale perturbation based on temperature\n",
    "    perturbation = np.random.normal(0, temperature, size=weights.shape)\n",
    "    return weights + perturbation\n",
    "\n",
    "# Main function to apply Simulated Annealing optimization\n",
    "def optimize_nn_with_sa(model, dataloader, input_size, hidden_size, output_size, \n",
    "                       initial_temp=1.0, final_temp=0.01, cooling_rate=0.95,\n",
    "                       iterations_per_temp=20, max_iterations=1000):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize current solution\n",
    "    current_weights = get_flat_weights(model)\n",
    "    current_loss = calculate_loss(current_weights, model, dataloader, criterion)\n",
    "    \n",
    "    # Keep track of the best solution\n",
    "    best_weights = current_weights.copy()\n",
    "    best_loss = current_loss\n",
    "    \n",
    "    # Initialize temperature\n",
    "    temperature = initial_temp\n",
    "    iteration = 0\n",
    "    \n",
    "    while temperature > final_temp and iteration < max_iterations:\n",
    "        for _ in range(iterations_per_temp):\n",
    "            # Generate neighbor solution\n",
    "            neighbor_weights = generate_neighbor(current_weights, temperature)\n",
    "            neighbor_loss = calculate_loss(neighbor_weights, model, dataloader, criterion)\n",
    "            \n",
    "            # Calculate acceptance probability\n",
    "            delta_loss = neighbor_loss - current_loss\n",
    "            acceptance_prob = np.exp(-delta_loss / temperature)\n",
    "            \n",
    "            # Accept or reject the neighbor solution\n",
    "            if delta_loss < 0 or np.random.random() < acceptance_prob:\n",
    "                current_weights = neighbor_weights\n",
    "                current_loss = neighbor_loss\n",
    "                \n",
    "                # Update best solution if necessary\n",
    "                if current_loss < best_loss:\n",
    "                    best_weights = current_weights.copy()\n",
    "                    best_loss = current_loss\n",
    "                    print(f'Iteration {iteration}, Temperature: {temperature:.6f}, New Best Loss: {best_loss:.6f}')\n",
    "            \n",
    "            # Early stopping if loss is good enough\n",
    "            if best_loss < 0.1:\n",
    "                print(f\"Optimization converged at iteration {iteration}\")\n",
    "                break\n",
    "            \n",
    "        iteration += 1\n",
    "        # Cool down the temperature\n",
    "        temperature *= cooling_rate\n",
    "        print(f'Temperature decreased to {temperature:.6f}, Current best loss: {best_loss:.6f}')\n",
    "    \n",
    "    # Set the best weights to the model\n",
    "    idx = 0\n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()\n",
    "        param.data = torch.tensor(best_weights[idx: idx + num_params].reshape(param.shape), dtype=torch.float32)\n",
    "        idx += num_params\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage with synthetic dataset\n",
    "if __name__ == \"__main__\":\n",
    "    # Create synthetic dataset\n",
    "    X = torch.randn(100, 10)  # 100 samples, 10 features\n",
    "    y = torch.randint(0, 2, (100,))  # Binary classification\n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    input_size = 10\n",
    "    hidden_size = 64\n",
    "    output_size = 2\n",
    "    model = SimpleNN(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # Optimize using Simulated Annealing\n",
    "    optimized_model = optimize_nn_with_sa(\n",
    "        model, \n",
    "        dataloader,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "        initial_temp=0.3,\n",
    "        final_temp=0.01,\n",
    "        cooling_rate=0.99,\n",
    "        iterations_per_temp=20,\n",
    "        max_iterations=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1/16, Layer 1 Error: 12.338958740234375, Layer 2 Error: 1.5570337772369385, Output Layer Error: 1.2001296281814575\n",
      "Epoch 1/10, Batch 11/16, Layer 1 Error: 11.755592346191406, Layer 2 Error: 1.5227323770523071, Output Layer Error: 1.3459597826004028\n",
      "Epoch 1 Accuracy: 9.20%\n",
      "Epoch 2/10, Batch 1/16, Layer 1 Error: 11.973122596740723, Layer 2 Error: 1.5104399919509888, Output Layer Error: 1.3485537767410278\n",
      "Epoch 2/10, Batch 11/16, Layer 1 Error: 11.890755653381348, Layer 2 Error: 1.5272572040557861, Output Layer Error: 1.2575950622558594\n",
      "Epoch 2 Accuracy: 9.20%\n",
      "Epoch 3/10, Batch 1/16, Layer 1 Error: 11.53770637512207, Layer 2 Error: 1.5421624183654785, Output Layer Error: 1.2790231704711914\n",
      "Epoch 3/10, Batch 11/16, Layer 1 Error: 11.588460922241211, Layer 2 Error: 1.4892184734344482, Output Layer Error: 1.2089152336120605\n",
      "Epoch 3 Accuracy: 9.20%\n",
      "Epoch 4/10, Batch 1/16, Layer 1 Error: 11.133646965026855, Layer 2 Error: 1.4296085834503174, Output Layer Error: 1.2938807010650635\n",
      "Epoch 4/10, Batch 11/16, Layer 1 Error: 11.833728790283203, Layer 2 Error: 1.6978954076766968, Output Layer Error: 1.2992784976959229\n",
      "Epoch 4 Accuracy: 9.20%\n",
      "Epoch 5/10, Batch 1/16, Layer 1 Error: 12.056408882141113, Layer 2 Error: 1.473961591720581, Output Layer Error: 1.2101515531539917\n",
      "Epoch 5/10, Batch 11/16, Layer 1 Error: 12.073298454284668, Layer 2 Error: 1.54996919631958, Output Layer Error: 1.2624881267547607\n",
      "Epoch 5 Accuracy: 9.20%\n",
      "Epoch 6/10, Batch 1/16, Layer 1 Error: 12.069731712341309, Layer 2 Error: 1.4670274257659912, Output Layer Error: 1.136982798576355\n",
      "Epoch 6/10, Batch 11/16, Layer 1 Error: 11.132034301757812, Layer 2 Error: 1.5060745477676392, Output Layer Error: 1.2422212362289429\n",
      "Epoch 6 Accuracy: 9.20%\n",
      "Epoch 7/10, Batch 1/16, Layer 1 Error: 11.908493995666504, Layer 2 Error: 1.533594012260437, Output Layer Error: 1.2317745685577393\n",
      "Epoch 7/10, Batch 11/16, Layer 1 Error: 11.235333442687988, Layer 2 Error: 1.413226842880249, Output Layer Error: 1.2835774421691895\n",
      "Epoch 7 Accuracy: 9.20%\n",
      "Epoch 8/10, Batch 1/16, Layer 1 Error: 12.193942070007324, Layer 2 Error: 1.4773136377334595, Output Layer Error: 1.2516727447509766\n",
      "Epoch 8/10, Batch 11/16, Layer 1 Error: 11.432159423828125, Layer 2 Error: 1.5266876220703125, Output Layer Error: 1.1708898544311523\n",
      "Epoch 8 Accuracy: 9.20%\n",
      "Epoch 9/10, Batch 1/16, Layer 1 Error: 12.023479461669922, Layer 2 Error: 1.47810697555542, Output Layer Error: 1.2380155324935913\n",
      "Epoch 9/10, Batch 11/16, Layer 1 Error: 11.506525039672852, Layer 2 Error: 1.5371804237365723, Output Layer Error: 1.3131937980651855\n",
      "Epoch 9 Accuracy: 9.20%\n",
      "Epoch 10/10, Batch 1/16, Layer 1 Error: 11.832963943481445, Layer 2 Error: 1.5343163013458252, Output Layer Error: 1.1771140098571777\n",
      "Epoch 10/10, Batch 11/16, Layer 1 Error: 11.721725463867188, Layer 2 Error: 1.3711702823638916, Output Layer Error: 1.351419448852539\n",
      "Epoch 10 Accuracy: 9.20%\n",
      "\n",
      "Final Evaluation:\n",
      "Final Accuracy: 9.20%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
